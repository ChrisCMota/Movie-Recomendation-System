{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7b12f1",
   "metadata": {},
   "source": [
    "# Train Hybrid Movie Recommender System\n",
    "\n",
    "This notebook trains:\n",
    "- A content-based recommendation model using TF-IDF + Nearest Neighbors\n",
    "- A collaborative filtering model using SVD (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf882ce",
   "metadata": {},
   "source": [
    "## Step 1: Load and Clean Dataset\n",
    "\n",
    "Clean and complete data ensures both recommendation models operate without error or bias.\n",
    "\n",
    "### What it Does\n",
    "Loads the CSV dataset and removes rows with missing values for genre, rating, or votes. This ensures input consistency for the TF-IDF and SVD algorithms.\n",
    "\n",
    "- `Pandas` for data, `joblib` for saving models, `time` for tracking duration, `os` for file management.\n",
    "- `TF-IDF vectorizer` converts genres into numerical vectors based on term frequency so that we can calculate similarity between movies mathematically.\n",
    "- `NearestNeighbors` finds similar movies by genre vectors.\n",
    "- `surprise` classes for collaborative filtering used to build a rating prediction model. We need to build a rating prediction model to estimate how much a user would like a movie they have not rated yet.\n",
    "\n",
    "\n",
    "### Variables\n",
    "- `movies_df`: DataFrame containing the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d033c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading cleaned dataset...\n",
      "[INFO] Movies loaded: 100000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from surprise import Dataset, Reader, SVD\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"[INFO] Loading cleaned dataset...\")\n",
    "movies_df = pd.read_csv(\"cleaned_imdb_movies.csv\")\n",
    "movies_df = movies_df.dropna(subset=[\"genres\", \"averageRating\", \"numVotes\"])\n",
    "movies_df = movies_df[movies_df[\"genres\"].str.strip().astype(bool)]\n",
    "print(\"[INFO] Movies loaded:\", len(movies_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124afa1e",
   "metadata": {},
   "source": [
    "## Step 2: TF-IDF Genre Vectorization\n",
    "\n",
    "To numerically represent genres for similarity computation, we apply TF-IDF a widely-used algorithm in NLP(Natural Language Processing) that emphasizes distinct terms.\n",
    "\n",
    "`NLP` is the field of AI that enables computers to understand, interpret, and generate human language.\n",
    "\n",
    "Removes common English words when vectorizing.\n",
    "\n",
    "`TF-IDF` stands for Term Frequency – Inverse Document Frequency. It measures how important a word is in a document compared to a collection of documents.\n",
    "\n",
    "In TF-IDF, a `document` = the genre(s) of one movie.\n",
    "\n",
    "### What it Does\n",
    "Transforms genre text using TF-IDF into a matrix where rows represent movies and columns represent genre terms. Each cell reflects term importance.\n",
    "\n",
    "### Variables\n",
    "- `tfidf_vectorizer`: Fitted TF-IDF model.\n",
    "- `tfidf_matrix`: TF-IDF score matrix for genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0baf434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting TF-IDF vectorization...\n",
      "[DONE] TF-IDF shape: (100000, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Starting TF-IDF vectorization...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df[\"genres\"])\n",
    "print(f\"[DONE] TF-IDF shape: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba3a14",
   "metadata": {},
   "source": [
    "## Step 3: Train Nearest Neighbors Model\n",
    "\n",
    "To find genre-similar movies, we use k-Nearest Neighbors (k-NN) with cosine similarity on the TF-IDF matrix.\n",
    "- Cosine similarity is a metric used to measure how similar two vectors are — based on the angle between them.\n",
    "- k-Nearest Neighbors (k-NN) is an algorithm that finds the most similar items to a given item by measuring distances between their feature vectors.\n",
    "\n",
    "`Cosine` measures the angle between two vectors to determine how similar they are, regardless of their size.\n",
    "\n",
    "For our training, using cosine means we are comparing movies based on the similarity of their genres’ direction, not their absolute counts, making recommendations more accurate even if movies have different numbers of genres.\n",
    "\n",
    "### What it Does\n",
    "Trains NearestNeighbors with cosine distance to find the top 50 similar movies for each item.\n",
    "\n",
    "### Variables\n",
    "- `nn_model`: NearestNeighbors model. Builds a brute-force cosine similarity search model. Prepares it to find the closest movies.\n",
    "- `distances`, `indices`: Results of the nearest neighbor lookup. Finds nearest neighbors. Stores the most similar movies for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6be452e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Fitting NearestNeighbors model...\n",
      "[INFO] Computing all neighbors...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Fitting NearestNeighbors model...\")\n",
    "nn_model = NearestNeighbors(n_neighbors=50, metric=\"cosine\", algorithm=\"brute\")\n",
    "nn_model.fit(tfidf_matrix)\n",
    "\n",
    "print(\"[INFO] Computing all neighbors...\")\n",
    "distances, indices = nn_model.kneighbors(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b8523",
   "metadata": {},
   "source": [
    "## Step 4: Save Content-Based Models\n",
    "\n",
    "Saving models avoids retraining and allows integration into APIs or apps for real-time use.\n",
    "\n",
    "### What it Does\n",
    "Saves the trained TF-IDF vectorizer and nearest neighbors indices to disk.\n",
    "\n",
    "### Variables\n",
    "- Saved files: `tfidf_vectorizer.pkl`, `nearest_neighbors_indices.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "457131d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] TF-IDF vectorizer saved.\n",
      "[SAVED] Nearest Neighbors indices saved.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(tfidf_vectorizer, \"models/tfidf_vectorizer.pkl\")\n",
    "print(\"[SAVED] TF-IDF vectorizer saved.\")\n",
    "joblib.dump(indices, \"models/nearest_neighbors_indices.pkl\")\n",
    "print(\"[SAVED] Nearest Neighbors indices saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ac60a",
   "metadata": {},
   "source": [
    "## Step 5: Simulate Users for SVD\n",
    "\n",
    "SVD is a collaborative filtering algorithm requiring user-item interactions. We simulate 1000 users using modulo logic.\n",
    "\n",
    "SVD (Singular Value Decomposition) is a mathematical technique that breaks down a large matrix (like user-movie ratings) into smaller parts to uncover hidden relationships between users and items.\n",
    "\n",
    "We need SVD because it helps predict how a user would rate movies they have not seen yet by learning hidden patterns between users and movies from the existing ratings.\n",
    "\n",
    "### What it Does\n",
    "Adds `user_id` and reformats the DataFrame into Surprise's required dataset structure.\n",
    "\n",
    "The IMDb data only had movie titles and their average rating (for everyone). We assigned each movie to a simulated user ID ,and we used the movie’s averageRating as if it was the user’s personal rating.\n",
    "\n",
    "### Variables\n",
    "Inputs for SVD training.\n",
    "- `reader`: Creates a Reader object from the Surprise library, and defines that all ratings are between 0 (minimum) and 10 (maximum).\n",
    "- `data`: Loads the user-movie-rating data into a Surprise Dataset. Reader parses and structures the data properly. This is needed to feed the collaborative model (SVD) — it expects user-item-rating triplets.\n",
    "-  `trainset`: Converts the Dataset into a Trainset object used by Surprise models. Use 100% of the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c13f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preparing data for SVD...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Preparing data for SVD...\")\n",
    "movies_df[\"user_id\"] = movies_df.index % 1000 # Creates a new column called user_id in the movies_df DataFrame with fake user IDs ranging from 0 to 999.\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "data = Dataset.load_from_df(movies_df[[\"user_id\", \"primaryTitle\", \"averageRating\"]], reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02a85b",
   "metadata": {},
   "source": [
    "## Step 6: Train and Save SVD Model\n",
    "\n",
    "SVD factorizes user-movie interactions into latent dimensions to predict future ratings.\n",
    "\n",
    "### What it Does\n",
    "Trains the SVD model with 50 latent features and saves it for prediction.\n",
    "\n",
    "### Variables\n",
    "- `svd_model`: Trained model.\n",
    "- File saved: `svd_model.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b17d6a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training SVD model...\n",
      "[SAVED] SVD model saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Training SVD model...\")\n",
    "svd_model = SVD(n_factors=50, n_epochs=10)\n",
    "svd_model.fit(trainset)\n",
    "joblib.dump(svd_model, \"models/svd_model.pkl\")\n",
    "print(\"[SAVED] SVD model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e86f8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models trained and saved in 249.83 seconds\n"
     ]
    }
   ],
   "source": [
    "elapsed = time.time() - start_time\n",
    "print(f\"All models trained and saved in {elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d073c4b-8fbf-46fe-8947-772bdbbb46fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
